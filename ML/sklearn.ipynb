{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "# text\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer, TfidfVectorizer\n",
    "# classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso #  модель линейной регрессии со встроенной L1-регуляризацией весов (ограничение на сумму модулей весов).\n",
    "from sklearn.linear_model import Ridge # модель линейной регрессии со встроенной L2-регуляризацией весов (ограничение на сумму квадратов весов).\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# classterization\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, SpectralClustering, DBSCAN, MiniBatchKMeans\n",
    "# preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, label_binarize, OneHotEncoder\n",
    "# mertrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# embedding vectors\n",
    "# Важно\n",
    "# It is highly recommended to use another dimensionality reduction method (e.g. PCA for dense data or TruncatedSVD for sparse data)  \n",
    "# to reduce the number of dimensions to a reasonable amount (e.g. 50) if the number of features is very high.  \n",
    "# This will suppress some noise and speed up the computation of pairwise distances between samples\n",
    "from sklearn.manifold import TSNE\n",
    "# reduce the dimensionality\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "import string\n",
    "import random\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date,datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем набор данных\n",
    "iris_df = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lable encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "если порядок совпадает с ожидаемым, то есть по алфавиту буквы идут и подходит, что будет от 0 до n  \n",
    "или нам не важно какая буква будет с какой цифорой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "l = ['a', 'c', 'b', 'd', 'e']\n",
    "\n",
    "le.fit_transform(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "если нам нужно правильный порядок сделать, то используем label_binarize  \n",
    "label_binarize делает one hot encoding, и если нам нужно от 0 до n, то используем argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2, 1, 4], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "l = ['bad', 'excellent', 'medium', 'very good', 'very bad']\n",
    "\n",
    "label_binarize(l, classes=['excellent', 'very good', 'medium', 'bad', 'very bad']).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "l = ['bad', 'excellent', 'medium', 'very good', 'very bad']\n",
    "\n",
    "label_binarize(l, classes=['excellent', 'very good', 'medium', 'bad', 'very bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор признаков, которые лучше других влияют на модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3252302 ,  0.83462377,  0.49750423]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = [[ 0.87, -1.34,  0.31 ],\n",
    "     [-2.79, -0.02, -0.85 ],\n",
    "     [-1.34, -0.48, -2.55 ],\n",
    "     [ 1.92,  1.48,  0.65 ]]\n",
    "y = [0, 1, 0, 1]\n",
    "selector = SelectFromModel(estimator=LogisticRegression()).fit(X, y)\n",
    "selector.estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порог, по которому селектор разбивает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат в вдие булевых значений после сравнения порого и коэффициентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь забираем только важные признаки для этой модели\n",
    "По сути просто берем фичи, у которых истина после разделения по селекторву"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.34],\n",
       "       [-0.02],\n",
       "       [-0.48],\n",
       "       [ 1.48]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "\n",
    "selector = SelectFromModel(estimator=DecisionTreeClassifier()).fit(X, y)\n",
    "dt = DecisionTreeClassifier().fit(X, y)\n",
    "selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.threshold_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сокращение размерности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99244289 0.00755711]\n",
      "[6.30061232 0.54980396]\n",
      "\n",
      "[[-0.83849224 -0.54491354]\n",
      " [ 0.54491354 -0.83849224]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "PCA(n_components=2)\n",
    "# Чтобы проверить соотношение дисперсии, объясненную этим СПС, мы можем рассмотреть pca.explained_variance_ratio_ :\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n",
    "print()\n",
    "# линейные комбинации\n",
    "# Обратите внимание, что первые два компонента в каждом векторе на несколько порядков больше других, что показывает,   \n",
    "# что СПС признал, что дисперсия содержится главным образом в первых двух столбцах\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after PCA: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "data = datasets.load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Разделение данных на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Применение PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Обучение SVM (C-Support Vector Classification) на данных после PCA\n",
    "svm = SVC()\n",
    "svm.fit(X_train_pca, y_train)\n",
    "\n",
    "# Оценка производительности модели\n",
    "accuracy = svm.score(X_test_pca, y_test)\n",
    "print(f'Accuracy after PCA: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01570766 0.05122679 0.04998062 0.04795064 0.04539933]\n",
      "0.21026503465070323\n",
      "[35.24105443  4.5981613   4.54200434  4.44866153  4.32887456]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "X_dense = np.random.rand(100, 100)\n",
    "X_dense[:, 2 * np.arange(50)] = 0\n",
    "X = csr_matrix(X_dense)\n",
    "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "svd.fit(X)\n",
    "TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(svd.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример данных\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "lemma = nltk.WordNetLemmatizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Загрузка данных\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "random.shuffle(documents)\n",
    "# Подготовка данных\n",
    "texts = [' '.join(doc) for doc, _ in documents]\n",
    "labels = [1 if category == 'pos' else 0 for _, category in documents]\n",
    "prep_text = []\n",
    "# Токенизация и лематизация\n",
    "for sentence in texts:\n",
    "    sentence = sentence.lower()\n",
    "    tokens = word_tokenize(sentence)\n",
    "    lem_tokens = [lemma.lemmatize(token) for token in tokens]\n",
    "    lem_filt_tokens = [token for token in lem_tokens if token not in stop_words and token not in punctuation]\n",
    "    prep_sentence = ' '.join(lem_filt_tokens)\n",
    "    prep_text.append(prep_sentence)\n",
    "   \n",
    "# Создание BoW модели\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(prep_text)\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, labels, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8033333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       304\n",
      "           1       0.81      0.79      0.80       296\n",
      "\n",
      "    accuracy                           0.80       600\n",
      "   macro avg       0.80      0.80      0.80       600\n",
      "weighted avg       0.80      0.80      0.80       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение классификатора\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       304\n",
      "           1       0.84      0.82      0.83       296\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.84      0.83      0.83       600\n",
      "weighted avg       0.84      0.83      0.83       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучение классификатора\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение классификатора\n",
    "classifier = LinearDiscriminantAnalysis()\n",
    "classifier.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение классификатора\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Оценка классификатора\n",
    "predictions = classifier.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "\n",
    "print(classification_report(y_test, predictions, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso регуляризация (регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# прочитайте данные с атрибутами аккаунтов компаний на Facebook и активностью на них\n",
    "fb = pd.read_csv('/datasets/dataset_facebook_cosmetics.csv', sep = ';')\n",
    "# разделяем данные на признаки (матрица X) и целевую переменную (y)\n",
    "X = fb.drop('Total Interactions', axis = 1)\n",
    "y = fb['Total Interactions']\n",
    "# разделяем модель на обучающую и валидационную выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# стандартизируем данные методом StandartScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_st = scaler.transform(X_train)\n",
    "X_test_st = scaler.transform(X_test)\n",
    "model = Ridge() # создаём модель класса Ridge-регрессия\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators — число деревьев, на основании которых будем строить лес, глубину дерева max_depth, размер подвыборки признаков max_features, минимальное количество объектов в узле min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# зададим алгоритм для новой модели на основе алгоритма случайного леса\n",
    "rf_model = RandomForestRegressor(n_estimators = 100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# зададим алгоритм для новой модели на основе алгоритма градиентного бустинга\n",
    "gb_model = GradientBoostingRegressor(n_estimators = 100)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическя регрессия и установка порога отсечения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем набор данных Iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[iris.target != 2]  # Используем только два класса\n",
    "y = iris.target[iris.target != 2]\n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель логистической регрессии\n",
    "model = LogisticRegression()\n",
    "# Обучаем модель\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказываем вероятности для тестовой выборки\n",
    "probabilities = model.predict_proba(X_test)\n",
    "# Предсказываем классы на основе стандартного порога 0.5\n",
    "predictions = model.predict(X_test)\n",
    "# Выводим вероятности и предсказанные классы\n",
    "print(\"Предсказанные вероятности:\\n\", probabilities)\n",
    "print(\"Предсказанные классы:\\n\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В матрице путаницы каждая строка соответствует реальному классу, а каждый столбец — предсказанному классу.  \n",
    "Следовательно True Positive будут значения на главной диагонали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Точность модели:\", accuracy)\n",
    "\n",
    "# Выводим матрицу путаницы и отчет о классификации\n",
    "print(\"Матрица путаницы:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Отчет о классификации:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нам нужно установить свой порог (например, у нас классы несбалансированы), то делаем так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установите новый порог\n",
    "threshold = 0.7\n",
    "# Предсказание вероятностей для тестовой выборки\n",
    "probabilities = model.predict_proba(X_test)\n",
    "# Классификация на основе нового порога\n",
    "predictions = (probabilities[:, 1] >= threshold).astype(int)\n",
    "# Выводим предсказанные классы\n",
    "print(\"Предсказанные классы с порогом 0.7:\\n\", predictions)\n",
    "# Оценка точности модели с новым порогом\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Точность модели с порогом 0.7:\", accuracy)\n",
    "# Выводим матрицу путаницы и отчет о классификации\n",
    "print(\"Матрица путаницы с порогом 0.7:\\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"Отчет о классификации с порогом 0.7:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для бинарного классификатора важно постриоть Roc-Auc кривую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Загрузка данных\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "# Обучение модели\n",
    "model = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "model.fit(X, y)\n",
    "# Получение предсказанных вероятностей\n",
    "y_scores = model.predict_proba(X)[:, 1]\n",
    "# Вычисление ROC-кривой\n",
    "fpr, tpr, thresholds = roc_curve(y, y_scores)\n",
    "# Вычисление AUC\n",
    "roc_auc = roc_auc_score(y, y_scores)\n",
    "# Построение ROC-кривой с использованием Plotly\n",
    "fig = go.Figure()\n",
    "# Добавляем линию ROC-кривой\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='ROC Curve (AUC = {:.2f})'.format(roc_auc),\n",
    "                          line=dict(color='blue', width=2)))\n",
    "# Добавляем линию случайного угадывания\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Random Guessing',\n",
    "                          line=dict(color='red', dash='dash')))\n",
    "# Настройка графика\n",
    "fig.update_layout(title='Receiver Operating Characteristic (ROC) Curve',\n",
    "                  xaxis_title='False Positive Rate',\n",
    "                  yaxis_title='True Positive Rate',\n",
    "                  xaxis=dict(range=[0, 1]),\n",
    "                  yaxis=dict(range=[0, 1]),\n",
    "                  showlegend=True)\n",
    "# Отображение графика\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Класстеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По ссылке можно посмотреть базовые преимущества и недостатки методов кластеризации <br>\n",
    "https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Описываем модель\n",
    "model = KMeans(n_clusters=3)\n",
    "# Проводим моделирование\n",
    "model.fit(iris_df.data)\n",
    "# Предсказание на всем наборе данных\n",
    "all_predictions = model.predict(iris_df.data)\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# определим функцию, которая будет выводить наши метрики\n",
    "def print_all_metrics(y_true, y_pred, y_proba, title='Метрики классификации'):\n",
    "    print(title)\n",
    "    print('\\tAccuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))\n",
    "    print('\\tPrecision: {:.2f}'.format(precision_score(y_true, y_pred)))\n",
    "    print('\\tRecall: {:.2f}'.format(recall_score(y_true, y_pred)))\n",
    "    print('\\tF1: {:.2f}'.format(f1_score(y_true, y_pred)))\n",
    "    print('\\tROC_AUC: {:.2f}'.format(roc_auc_score(y_true, y_proba)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pagri-projects-W8_aXYna-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
